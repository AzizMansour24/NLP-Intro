# 🧠 Natural Language Processing (NLP) Project

Welcome to the **NLP.ipynb** notebook! This project walks through the essential steps of **Natural Language Processing (NLP)** using Python — from raw text to clean, structured data ready for modeling or analysis.

---

## 📌 Table of Contents
- [🔧 Libraries Used](#-libraries-used)
- [🧼 Text Preprocessing](#-text-preprocessing)
- [🧪 Regular Expressions](#-regular-expressions)
- [🔗 Tokenization](#-tokenization)
- [🌱 Stemming vs Lemmatization](#-stemming-vs-lemmatization)
- [🧊 N-Grams](#-n-grams)
- [📚 Exercises](#-exercises)
- [🚀 How to Run](#-how-to-run)

---

## 🔧 Libraries Used
The notebook starts by importing all the necessary Python libraries for NLP, including:
- `re`
- `nltk`
- `pandas`
- `matplotlib`

---

## 🧼 Text Preprocessing
Includes key steps like:
- Lowercasing text
- Removing stop words
- Applying regular expressions
- Tokenization

---

## 🧪 Regular Expressions
Learn how to:
- Search patterns in text
- Use `re.sub()` to clean and transform
- Apply advanced regex like `r"(need|want)ed"` or `r"^\w"`

---

## 🔗 Tokenization
Split sentences and paragraphs into individual words or tokens using:
- NLTK’s `word_tokenize`
- Custom regex patterns

---

## 🌱 Stemming vs Lemmatization
Understand the difference:
- **Stemming:** Cuts off prefixes/suffixes (e.g., “worse” → “wors”)
- **Lemmatization:** More intelligent (e.g., “better” → “good”)

---

## 🧊 N-Grams
Generate and analyze:
- Bigrams
- Trigrams
- Any n-length sequences of words

---

## 📚 Exercises
Hands-on preprocessing examples:
- Cleaning text data
- Applying your own regex
- Visualizing text features

---

## 🚀 How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/nlp-project.git
   cd nlp-project
